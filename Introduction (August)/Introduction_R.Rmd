---
title: 'Introduction to R'
author: 'Victoria Zaitceva'
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
library(tidyverse)
```

# Dataframe vs Tibble

```{r}
# create a datafrme with data.frame()) function
df <- data.frame(
  name = c('John', 'Paul', 'George', 'Ringo'),
  age = c(40, 50, 60, 70),
  stringsAsFactors = FALSE #default is TRUE
)

df

```



```{r}
# create the same dataframe with tibble() function
library(tibble)
df1 <- tibble(
  name = c('John', 'Paul', 'George', 'Ringo'),
  age = c(40, 50, 60, 70) #strings are not converted to factors when using tibble()
)

# create dataframe from vectors
name <- c('John', 'Paul', 'George', 'Ringo')
age <- c(40, 50, 60, 70)
df1 <- tibble(name, age)


df1
```

You don't really see the difference between data.frame and tibble when you print them out in markdown. But there are some differences in the way they are printed out in the console. 

Tibble is more tidy and easier to read. 
Also, it doesn't convert strings to factors by default and shows only the first 10 rows and the type of the columns. 

tibble Оценивает аргументы лениво и последовательно. 
*Ленивая оценка аргументов* — возможность создавать переменные на основе уже существующих.

```{r}
tibble(var1 = 1:5,
       var2 = var1*2)
```
# Dataframe manupulation

```{r}
tsv <- read.csv('https://stepik.org/media/attachments/course/122402/data_tsv.tsv', sep = '\t', header = TRUE)
```


### tibble::add_column() and tibble::add_row()

Эта функция помогает просто добавить столбец/строку с заранее заданными значениями. Обратите внимание: его имя всё ещё должно быть уникальным.

```{r}
data %>% add_column(column_name = 1:10, .before = NULL, .after = NULL)
data %>% add_row(var_1 = 1, var_2 = "value", .before = NULL, .after = NULL)
```

data: просто имя датафрейма, к которому мы хотим добавить столбец;
column_name: это имя нового столбца. Оно может быть любым, не только таким, как в примере;
.before: номер уже существующего столбца, перед которым нужно поставить новый;
.after: то же, но уже после которого нужно поставить новый. Хитрый приём: если нужно поставить переменную в конец датафрейма, то в значение можно поставить Inf.
var_1, var_2: это имя столбца. Оно может быть любым, не только таким, как в примере;

B тех переменных, которые мы не указали явно, автоматически добавились пропущенные значения.

Переменная "Группа" раньше была фактором, но мы добавили к ней новое значение. С факторном переменной так делать нельзя, поэтому функция автоматически привела тип к строковому, следует помнить эту особенность. 

### dplyr::row_number()

Одна полезная функция, которая даёт возможность пронумеровать строки (добровольцев).

```{r}
library(dplyr)
tsv %>% mutate(ID = row_number())
```
### dplyr::bind_cols() and dplyr::bind_rows()

Мы можем сделать из двух и более таблиц одну, склеив их столбцы.

```{r}
data_1 %>% bind_cols(data_2) %>% bind_cols(data_3)
data_1 %>% bind_rows(data_2) %>% bind_rows(data_3)
```

Именно так мы можем сделать это. 
For bind_cols() в таблицах должно быть *одинаковое количество строк*, а переменные должны иметь разные имена. В ином случае будет возвращена ошибка.

For bind_rows() Нужно просто чтобы переменные были одинакового типа и назывались одинаково. Если они будут называться по-разному, то на месте "лишней" переменной будет NA.

# Группировка

### dplyr::group_by()

```{r}
tsv %>% group_by(Группа)
```


### base::split()

Одна полезная функция. Она разбивает датафрейм на список датафреймов по указанным группам. 

```{r}
tsv %>% split(.$Группа)

# save these dataframes separately
list_of_dfs <- tsv %>% split(.$Группа)
tsv_1 <- list_of_dfs[[1]]
tsv_2 <- list_of_dfs[[2]]
```


### dplyr::rowwise()

Группировка может производиться и по строкам, чтобы после применять полезные функции не по столбцам, а по строкам, как будто мы перевернули датафрейм.

```{r}

tsv %>% rowwise() %>% mutate(basophile_avr_for_2_visits = mean(c(Базофилы_E1, Визит_2), na.rm = TRUE))

```

```{r}
tsv %>% glimpse()
```

# Selecting Columns

Мы можем выбрать все переменные, кроме определённых.

```{r}
tsv %>% select(!'Группа')
```


Мы можем выбирать переменные не только по названиям, но и с помощью логический функций, возвращающих TRUE или FALSE. Применяя её, мы получаем вектор таких значений, из которых функция select() выбирает те, что имеют значение TRUE.

```{r}
tsv %>% select(contains('Базофилы')) #выбрать все переменные, содержащие "Базофилы"
tsv %>% select(where(is.numeric)) #выбрать все числовые переменные
tsv %>% select('Группа', contains('Базофилы'), where(is.numeric)) #mix
```
### Complex select() with functions

```{r}
 #выбрать переменные, среднее значение которых больше 10

tsv %>%
  select('Группа', where(~ is.numeric(.x) && mean(.x, na.rm = TRUE) > 10))

```


```{r}
tsv %>% select(where(is.numeric)) %>% 
  select(where(function(x) sd(x, na.rm = T) > 2 | mean(x, na.rm = T) < 10 | median(x, na.rm = T) > 5))
```
```{r}
tsv %>% select(!where(is.numeric))
```
### Иерархия операторов

Приоритет логических операторов от высшего к низшему. 

1. x < y, x > y, x <= y, x => y, x == y, x != y (операторы сравнения)
2. !x (логическое НЕ)
3. x & y (логическое И)
4. x | y (логическое ИЛИ)


## tidyselect package

tidyselect package provides a lot of useful functions for selecting columns. 

### contains, starts_with, ends_with, matches

```{r}
tsv %>% select(starts_with('Базофилы'))
tsv %>% select(contains('1'))

tsv %>% select(matches('_E\\d{1}')) #все переменные, у которых в названии после "_E" стоит ровно одна любая цифра (от 0 до 9, у нас всего 10 цифр)

tsv %>% select(starts_with('Базофилы') & ends_with('2')) #выбрать все переменные, начинающиеся на "Базофилы" и заканчивающиеся на "2"
```
 
### all_of, any_of, everything

```{r}
cols <- c('Группа', 'Базофилы_E1', 'Базофилы_E2')
tsv %>% select(cols) #it is fine, but better use all_of()

#Для того, чтобы функция выдавала ошибку, если отсутствует хотя бы одна из переменных, внутри select() следует использовать all_of()

tsv %>% select(all_of(cols)) #the same result but no warning

tsv %>% select(any_of(cols)) #выбрать все переменные, которые есть в cols


```

### everything()

Есть простая функция, которая просто значит "все остальные столбцы, кроме тех, которые уже были указаны". Например, так мы можем выбрать определённые столбцы, а потом просто все остальные, которые будут выведены в том порядке, в котором они были, за исключением тех, что мы уже явно взяли.

```{r}
tsv %>% select('Группа', 'Базофилы_E1', everything())
```
Выбор с одновременным изменением имён

Мы можем выбирать переменные, одновременно изменяя их имена.


```{r}
tsv %>% select(Group = 'Группа', Basophils_E1 = 'Базофилы_E1')
```


# Filtering rows

### slice()

```{r}
tsv %>% slice(1:5)
tsv %>% slice_head(n = 5)
tsv %>% slice_tail(n = 5)

tsv %>% slice_head(prop = 0.1) #выбрать 10% строк
```

### Random sample with slice

```{r}
tsv %>% slice_sample(n = 5)
```


### slice_min() and slice_max()

Так мы можем выбрать только те подстроки, которые имеют минимум по заданной переменной. Так же, только наоборот, работает slice_max().

```{r}
tsv %>% slice_min(Базофилы_E1)
tsv %>% slice_max(Базофилы_E1)

tsv %>% slice_min(Базофилы_E1, n = 5)
```
### filter()

Для того, чтобы, фильтруя по категориальной переменной, выбрать сразу несколько значений, используется функция %in%.

### %in%

```{r}
tsv %>% filter(Группа.крови %in% c("A (II)", "O (I)") & Группа != 'Группа 1')
```
### between()

С количественной переменной не стоит использовать  %in%, лучше использовать between().

```{r}
tsv %>% filter(between(Возраст, 20, 30))
```

### near()

Для десятичных дробей бывает очень сложно и даже не нужно фильтровать по конкретному значению. В примере мы отфильтровали датасет по значению эозинофилов на первом визите так, чтобы значения были примерно 3.38 ± 0.1.

```{r}
tsv %>% filter(near(Эозинофилы_E1, 3.38, tol = 0.1))
```


### if_any() and if_all() for filtering

фильтруем данные по условию, чтобы все переменные, содержащие в названии "Базофилы", имели значение строго больше 1.5.

if_all(): This function checks if all specified columns (those containing 'Базофилы') meet the given condition (~ .x > 1.5).

if_any(): This function checks if at least one of the specified columns (those containing 'Базофилы') meets the condition (x > 1.5).

```{r}
tsv %>% filter(if_all(.cols = contains('Базофилы'), ~ .x > 1.5))
tsv %>% filter(if_all(.cols = contsins('Базофилы'), .fns = function(x) x > 1.5))

tsv %>% filter(if_any(.cols = contauns('Базофилы'), ~ .x > 1.5))
tsv %>% filter(if_any(.cols = contains('Базофилы'), .fns = function(x) x > 1.5))
```


### ~ .x > 1.5: 

This is a shorthand for writing an anonymous function in formula syntax, which is available in dplyr and purrr. The tilde (~) represents an anonymous function, and .x represents each column of the dataframe that matches the criteria (i.e., whether the value in each column is greater than 1.5).

The expression ~ .x > 1.5 is equivalent to writing function(x) x > 1.5.

### .fns = function(x) x > 1.5

function(x) x > 1.5: This is the traditional function definition in R.

Here, you are explicitly defining an anonymous function where x represents each column of the dataframe, and the function checks if x > 1.5.


### group_by() and filter

```{r}
tsv %>% group_by(Группа) %>% filter(mean(Базофилы_E1, na.rm = TRUE) > 0.5)
```



# Mutating columns

```{r}
tsv %>% mutate(Women_with_blood4 = if_else(Пол == 'Женский' & Группа.крови == "AB (IV)", 'Yes', 'No')) %>% select(Women_with_blood4, everything()) %>% arrange(Women_with_blood4)
```

**Oсновные арифметические операции с переменными:**

+: сложение;
-: вычитание;
`*`: умножение;
/: деление;
log(): натуральный логарифм;
log1p(): тот же логарифм, но прибавляющий к исходному значению единицу, чтобы избавиться от проблемы нуля;
exp(): возведение в экспоненту;
expm1(): возведение в экспоненту из значения минус один;
round(): округление до заданного количества знаков после запятой;
ceiling(): округление до ближайшего максимального целого числа;
floor(): округление до ближайшего минимального целого числа.


```{r}
tibble(var_1 = 1:10, var_2 = var_1 + 1.123) %>%
  mutate(var_3 = var_1 + var_2,
         var_4 = var_1 - var_2,
         var_5 = var_1 * var_2,
         var_6 = var_1 / var_2,
         var_7 = log(var_1),
         var_8 = log1p(var_1),
         var_9 = exp(var_1),
         var_10 = expm1(var_1),
         var_11 = round(var_2, 2),
         var_12 = ceiling(var_2),
         var_13 = floor(var_2))
```


### dplyr::case_when()

если нужно выдать более, чем два условия 

```{r}
tsv %>% mutate(Age_group = case_when(Возраст < 20 ~ '<20',
                                     between(Возраст, 20, 30)  ~ '20-30',
                                     Возраст > 30 ~ '>30') %>% as.factor()) %>%
  select(Age_group, Возраст)
```


### tidyr::na_if(), tidyr::replace_na()

Чтобы заменить пропущенные значения каким-нибудь определённым значением (например, вместо NA сделать "Нет данных"), используется функция replace_na().


```{r}
class(tsv$Группа.крови)

tsv %>% mutate(Группа.крови = replace_na(Группа.крови, 'Нет данных')) %>% select(Группа.крови)

# but what if Группа.крови is a factor?

tsv$Группа.крови <- as.factor(tsv$Группа.крови) #convert to factor
# now the code above will return error. we have to convert factor to character first, then to factor again

tsv %>% mutate(Группа.крови = Группа.крови %>% as.character() %>% replace_na('Нет данных') %>% as.factor()) %>% select(Группа.крови)
```

Предположим, у нас не может быть в данных третьей группы крови, и мы хотим заменить её на пропущенное значение. Выше пример того, как мы можем это сделать.

```{r}
tsv %>% mutate(Группа.крови = na_if(Группа.крови, "B (III)")) %>% select(Группа.крови)
tsv %>% mutate(Группа.крови = Группа.крови %>% na_if("B (III)")) %>% select(Группа.крови)
```

### NULL как удаление переменной

Мы можем легко удалить переменную через mutate().

```{r}
tsv %>% mutate(
  Группа = NULL
)
```

### dplyr::across()

Функция across() для применения других функций к подмножеству переменных

В dplyr есть очень интересная функция, которая позволяет применять другие функции одним применением. Это функция across().

В этой функции два основных аргумента: 

1. Выбор столбцов, к которым будем применять функции;
2. Сама функция.

Здесь мы применили функцию нормализации ко всем количественным переменным. 

```{r}
tsv %>% mutate(across(where(is.numeric), ~ (. - mean(.)) / sd(.)))
tsv %>% mutate(across(where(is.numeric), .fns = function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)))
```

А здесь только к тем, которые в названии содержат "E1".

```{r}
tsv %>% mutate(across(contains('E1'), ~ (. - mean(.)) / sd(.)))
```

здесь мы нормализуем только те переменные, среднее которых строго меньше 10.

```{r}

#tsv %>% mutate(across(function(x) mean(x, na.rm = TRUE) < 10, function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))) #error


tsv %>%
  mutate(across(
    where(is.numeric), 
    ~ if (mean(.x, na.rm = TRUE) < 10) {
        (.x - mean(.x, na.rm = TRUE)) / sd(.x, na.rm = TRUE)
      } else {
        .x
      }
  ))




```


### Итерация по строкам 

Изредка нужно итерироваться не по столбцам, а по строкам. Например, найти средние значения базофилов за оба визита. Вспомним функцию rowwise() и, наконец-то, применим её на практике.

```{r}
tsv %>% rowwise() %>% mutate(basophiles_mean = mean(c_across(contains('Базофилы')), na.rm = TRUE)) %>% 
  select(contains('Базофилы'), basophiles_mean)

```


### Применение mutate() к сгруппированным датафреймам

Иногда нужно мутировать новые переменные по сгруппированным датафреймам. Например, мы хотим сделать переменную, в которой для каждой группы будет рассчитано значение определённой переменной за вычетом среднего по этой группе. 


```{r}
tsv %>% group_by(Группа) %>% 
  mutate(across(contains('Базофилы'), ~ . - mean(., na.rm = TRUE))) %>% ungroup() %>%
  select(Группа, contains('Базофилы'))

```


# Переименование with dplyr

### rename()

```{r}
tsv %>% rename(Group = Группа, Basophils_E1 = Базофилы_E1)
```



### dplyr::rename_with(), stringi::stri_replace_all_regex()

Есть случаи, например, когда нам нужно заменить все коды имён на их человекочитаемые имена. Обычно для этого стоит применять связку из rename_with() и stri_replace_all_regex().

В качестве примера переименуем все коды визитов на их названия. E1 = Визит 1, E2 = Визит 2.


```{r}
library(stringi)

tsv %>% rename_with(function(x) x %>% stri_replace_all_regex(c('_E1', '_E2'), c('_Визит1', '_Визит2'), vectorize_all = FALSE)) %>% glimpse()

#same
tsv %>% rename_with(~ .x %>% stri_replace_all_regex(c('_E1', '_E2'), c('_Визит1', '_Визит2'), vectorize_all = FALSE)) %>% glimpse()


```
```{r}
tsv %>% rename_with(.cols = where(is.numeric), .fn = function(x) str_c(x, '_new')) %>% glimpse()

```
### := и !! для особых случаев переименования

Особый случай: мы хотим написать функцию, в которую будем подавать разные переменные для того, чтобы присвоить их значения столбцам.


```{r}
new_name <- 'New_name'

tsv %>% rename(!!new_name := Группа) %>% glimpse()

#rename the column currently named 'Группа' to 'New_name'

```



# Сортировка

```{r}
tsv %>% group_by(Группа) %>% arrange(Возраст, .by_group = TRUE)
# .bu_group = TRUE: сначала сортируем по группам, потом внутри группы
```


# Wide and long format


## tidyr::pivot_longer()

Длинный формат данных — это такой формат, в котором значения первого столбца повторяются и разделяют данные на "группы". Попробуем перевести наш датасет в длинный формат.

Мы перевели данные в длинный формат, сохранив группировку по "Группе". Теперь у нас есть переменная имён переменных (name), а также переменная с их значениями (value). 

```{r}
tsv %>% select(Группа, contains('E1')) %>%
  pivot_longer(!Группа)
```

## tidyr::pivot_wider()

```{r}
tsv %>% select(Группа, contains('E1')) %>%
  mutate(ID = row_number()) %>% #мы создаём ID, чтобы функция понимала уникальность строк. 
  pivot_longer(!c(Группа, ID)) %>% # !c(Группа, ID) means all columns except Группа and ID will be pivoted. 
  #All other columns will be converted into two columns: name (which holds the original column names) and value (which holds the corresponding values).
  pivot_wider(id_cols = ID) 


```
```{r}
tsv %>% 
  mutate(ID = row_number()) %>%
  select(ID, contains('_E'))
```

### distinct()

Обратите внимание, что функция берёт в каждой группе (в данном случае по переменной "Группа") только первую строку.

```{r}
tsv %>% distinct(Группа, .keep_all = TRUE)
# .keep_all = TRUE: сохранить все переменные, otherwise it returns only the column by which we are selecting
```
# Разделение и склеивание

### tidyr::separate()

Для того, чтобы разделить одну переменную на две по определённому разделителю, используется функция separate().

```{r}
tibble(
  var1 = rep(paste0('first part', '__', 'second part'), 10)) %>%
  separate(var1, into = c('var1', 'var2'), sep = '__')
```


### tidyr::unite()

Чтобы склеить переменную, мы можем использовать unite(). Приведём пример на основе предыдущего датафрейма.

```{r}
tibble(
  var1 = rep(paste0('first part', '__', 'second part'), 10)) %>%
  separate(var1, into = c('var1', 'var2'), sep = '__') %>%
  unite('new_var', var1, var2, sep = ' AND ')
```


# Basic statistics

### mean

rmean(x, trim = 0, na.rm = FALSE)

x: вектор типа numeric;
trim = 0: аргумент, говорящий, сколько процентов наибольших и наименьших значений нужно убрать перед тем, как вычислять среднее. Позволяет избавиться от выбросов;
na.rm = FALSE: если мы предполагаем, что в векторе могут встретиться пропущенные значения, то необходимо установить значение этого аргумента как TRUE, в ином случае результатом функции будет NA.

```{r}
mean(c(-19, -9, 19, 5, -14, 0, 34, -8, 34, 24, -11, 8, 33, 12, -6))
mean(c(-2, 16, -3, 16, -9, 7, 31))
mean(c(-13, 19, -24, NA, 30, 64, -53, NA, 50, 31, -58, -34, -3, -34, 77), na.rm = TRUE)
mean(c(1, -1, 5, -12, -12, 3, 8, -10, 0))
mean(c(76, 65, 71, 16, 60, 29, 71, 46, 45, 41))
mean(c(NA, NA, NA, NA, NA, NA, 3, NA, NA), na.rm = TRUE)
```

### median

```{r}
median(x, na.rm = FALSE)
```

x: вектор типа numeric;
na.rm = FALSE: если мы предполагаем, что в векторе могут встретиться пропущенные значения, то необходимо установить значение этого аргумента как TRUE, в ином случае результатом функции будет NA.

Медиана — это значение, меньше которого 50% значений. В случае, если количество элементов вектора чётное, медианой становится среднее значение двух "средних" элементов. 

```{r}
median(c(-15, 71, 77, 36, 66, -21, -48, -8))
median(c(1, 9, NA, 88, 2, NA, 42, NA, 4, 68, NA), na.rm = TRUE)
median(c(-92, -50, 54, 55, 84, 52, -55, -23, 36, -11, 22, 11, -7))
median(c(-91, -33, 13, 34, 34, 75, -80, -35, -90, -72, 70, 67, -100, -94, -18))
median(c(19, 89, 78, 38, 8, 17, 25, 60, 8, 43, 29, 6, 62, 41, 69, 97, 61, 83, 25, 24))
```


### min(), max()

```{r}
min(x, na.rm = FALSE)
max(x, na.rm = FALSE)
```


```{r}
minmax <- function(x) {
  min_val = min(x, na.rm = TRUE)
  max_val = max(x, na.rm = TRUE)
  return(paste('Min:', min_val, 'Max:', max_val))
}

minmax(c(90.48, 31.16, 44.4, 21.94, 84.37, 53.15, 81.15, 47.86, 63.23, 46.75, 102.73))
minmax(c(60.22, 31.91, 72.71, 52.49, 46.21, 60.39, 60.09))
minmax(c(48.11, 45.3, 58.42, 51.64, 62.07, 57.26, 49.69, 93.29, 81.18, 44.78, 55.1, 76.74, 58.08))
minmax(c(17.24, 35.77, 57.57, 30.15, 43.27, 77.56, 72.19, 40.45, 46.2, 39.92))
minmax(c(68.92, 44.15, 34.2, 34.12, 37.7, 73.95, 36.9, 59.26, 31.06, 55.79, 73.92, 68.04, 53.73, 90.7, 39.66))
```

### quantile()

Представим, что у нас есть вектор из чисел. Мы упорядочиваем его по возрастанию и теперь можем находить в нём такие числа, меньше или равен которым определённый процент других чисел. Это и есть квантили. Например, медиана — это просто 50% квантиль.

```{r}
quantile(x, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
```

x: это исходный вектор с числами;
probs = seq(0, 1, 0.25): вектор процентилей, то есть, сколько процентов элементов вектора должно быть меньше или равно искомого числа;
na.rm = FALSE: убирать ли пропущенные значения;
names = TRUE: прикреплять ли имена квантилей к значениям полученного вектора;
type = 7: есть несколько способов расчёта квантилей, но в общем случае можно использовать значение по умолчанию.

Обратим внимание на то, что эта функция может возвращать и конкретный квантиль, например, 95%.
Use probs = c(0.025, 0.975) to get 2.5% and 97.5% quantiles


```{r}
#get default quantiles
quantile(c(80.94, 44.46, 46.33, 65.1, 66.42, 104.43, 53.15, 48.41, 12.88, 51.1, 43.03, 40.3, 33.71, 55.1, 22.17))
quantile(c(26.17, 97.73, 24.81, 53.62, 87.72, 45.19, 45.7, 69.63, 36.76, 7.17))


#get 2.5% and 97.5% quantile
quantile(c(63.92, 35.85, 26.9, 48.92, 43.1, 66.94, 47.06, 56.54, 29.1, 58.88), probs = c(0.025, 0.975))


# get 5% and 95% quantile
quantile(c(32.05, 93.85, 85.52, 56.69, 23.69, 11.29, 51.44, 63.09, 65.65, 35.73, 60.15, 30.93, -4.2), probs = c(0.05, 0.95))
```
### var(), sd()

**Дисперсия** — это просто средний квадрат отклонений значений от среднего значения.

**Стандартное отклонение** — это квадратный корень из дисперсии, который измеряет отклонения в единицах переменной, а не в их квадратах.

```{r}
var(x, na.rm = TRUE)
```

x: это исходный вектор с числами;
na.rm = FALSE: убирать ли пропущенные значения.

```{r}
varsd <- function(x) {
  varval = round(var(x, na.rm = TRUE),2)
  sdval = round(sd(x, na.rm = TRUE),2)
  return(paste('Varience:', varval, 'Standard deviation:', sdval))
}

varsd(c(47.44, 62.44, 20.44, 72.75, 77.86, 13.74, 28.2, 50.47, 59.19, 69.04))
varsd(c(49.31, 44.47, 14.04, 44.43, 49.18, 40.73, 44.65, 41.91, 80.38, 80.09))
varsd(c(57.96, 20.81, 8.92, 14.03, 61.02, 25.69, 21.22, 49.56, 25.64, 28.31))
varsd(c(76.22, 65, 19.69, 29.84, 37.18, 70.93, 64.78, 61.66, 49.03, 51.56))
varsd(c(92.11, 56, 47.89, 62.96, 47.41, 37.05, 73.96, 53, 52.37, 85.23))
```

### IQR (Interquartile range)

Межквартильный интервал позволяет оценить изменчивость данных, меньше завися от выбросов. На самом деле его можно рассчитать, просто вычтя из 0.75 квантиля 0.25-й, однако в R существует и базовая функция.

```{r}
IQR(x, na.rm = FALSE, type = 7)
```

x: это исходный вектор с числами;
na.rm = FALSE: убирать ли пропущенные значения;
type = 7: так как эта функция вычисляется на основе квантилей, для неё тоже применим тип квантиля, однако чаще всего подходит значение по умолчанию.


```{r}
IQR(c(80.94, 44.46, 46.33, 65.1, 66.42, 104.43, 53.15, 48.41, 12.88, 51.1, 43.03, 40.3, 33.71, 55.1, 22.17))
IQR(c(26.17, 97.73, 24.81, 53.62, 87.72, 45.19, 45.7, 69.63, 36.76, 7.17))
IQR(c(63.92, 35.85, 26.9, 48.92, 43.1, 66.94, 47.06, 56.54, 29.1, 58.88))
```
### lenth()

Простейшая функция, которая позволяет вычислять количество значений вектора.

```{r, eval = TRUE}
length(1:10)
```
Зачастую в работе нам нужно включить в таблицы количество значений без пропущенных значений и количество именно пропущенных значений:

sum(!is.na(vec)): количество значений без учёта пропущенных;
sum(is.na(vec)): количество пропущенных значений.

### Стандартная ошибка среднего sd(x)/sqrt(length(x))

**Стандартная ошибка среднего** — это стандартное отклонение всех средних выборки. 

Для неё нет базовой функции, однако мы можем написать её. 

Нужно просто разделить стандартное отклонение на square root длины вектора. Разумеется, всё это без учёта пропущенных значений.

```{r}
se <- function(x) {
  return(sd(x, na.rm = TRUE)/sqrt(length(x)))
}

se(c(47.44, 62.44, 20.44, 72.75, 77.86, 13.74, 28.2, 50.47, 59.19, 69.04))
se(c(49.31, 44.47, 14.04, 44.43, 49.18, 40.73, 44.65, 41.91, 80.38, 80.09))
se(c(57.96, 20.81, 8.92, 14.03, 61.02, 25.69, 21.22, 49.56, 25.64, 28.31))
se(c(76.22, 65, 19.69, 29.84, 37.18, 70.93, 64.78, 61.66, 49.03, 51.56))
```
### summary()

Базовая функция, дающая нам сводку по всем типам переменных: 

- для количественных переменных возвращает: минимум, первый квартиль, медиану, среднее, третий квартиль, максимум;
- для категориальных/строковых переменных возвращает просто количество каждой категории.

```{r, eval = TRUE}
summary(mtcars)
```

## psyc package

## psyc::describe()

```{r}
describe(x, na.rm = TRUE, skew = FALSE, ranges = TRUE)
```

x: датафрейм с количественными переменными;
na.rm = TRUE: удалять ли пропущенные значения в переменных;
skew = TRUE: вычислять ли асимметрию;
ranges = TRUE: вычислять размах, то есть, разницу между максимумом и минимумом.

```{r}
library(psych)
df <- readRDS(url('https://stepik.org/media/attachments/lesson/790859/numeric_data.rds'))

describe(df)

```

## table(), prop.table()

Категориальные данные зачастую тоже нуждаются в более подробной статистике.

```{r}
table(x, useNA = 'always')
```

x: датафрейм с n переменными;
useNA = "always": делать ли сводку по пропущенным значениям.

Первая функция просто делает сводную таблицу в абсолютных значений. Наиболее часто она применяется для сочетания двух переменных. В случае, если мы попытаемся сделать это для более, чем двух переменных, третья переменная станет группирующей, в итоге получится список таблиц, где каждый пункт списка — значение этой группирующей переменной.

```{r}
df <- readRDS(url('https://stepik.org/media/attachments/lesson/790859/factor_data.rds'))

table(df$Группа, df$Пол)
prop.table(table(df$Группа, df$Пол)) 

```


# Summary statistics with tidyverse

## dplyr::summarise()/dplyr::summarize()

Всего может быть два основных типа таблиц: количественные и категориальные. Начнём с количественных и познакомимся с базовой функцией, в которой абсолютно неважно, через какую букву — s или z — писать её.

summarize() сводит переменные к указанному значению. Например, к среднему/медиане/стандартному отклонению и прочим полезным статистикам. 

```{r}
tsv %>% select(Группа, where(is.numeric)) %>%
  group_by(Группа) %>% 
  summarise(across(where(is.numeric), mean, na.rm = TRUE))


tsv %>% select(Группа, where(is.numeric)) %>%
  group_by(Группа) %>% 
  summarise(across(where(is.numeric), .fns = function(x) mean(x, na.rm = TRUE)))


tsv %>% select(Группа, where(is.numeric)) %>%
  group_by(Группа) %>% 
  summarise(across(where(is.numeric), ~ mean(., na.rm = TRUE)))

#same
```
## Формирование статистической таблицы для количественной переменной

### list() из функций для расчёта списка статистик

Чаще всего мы хотим рассчитать сразу много статистик для каждой количественной переменной, и мы можем сделать это с помощью списка из именованных функций.

```{r}
statistics <- list(
      `Количество субъектов` = ~length(.x) %>% as.character(),
      `Количество (есть данные)` = ~sum(!is.na(.x)) %>% as.character(),
      `Нет данных` = ~sum(is.na(.x)) %>% as.character(),
      `Ср. знач.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `Станд. отклон.` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `95% ДИ для среднего` = ~sd(.x, na.rm = TRUE) %>% round(2) %>% as.character(),
      `мин. - макс.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(min(.x, na.rm = TRUE) %>% round(2), " - ", max(.x, na.rm = TRUE) %>% round(2))),
      `Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `Q1 - Q3` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(quantile(.x, 0.25, na.rm = TRUE) %>% round(2), " - ", quantile(.x, 0.75, na.rm = TRUE) %>% round(2)))
)
```


Знак тильды (~) и .x внутри функции — это просто краткий способ записать function(x).
sum(!is.na(.x)) — проверка на то, что, чтобы переменная не была пустой (нельзя забывать проверить всё, что только возможно, чтобы не получить неожиданную ошибку);
Наконец, мы округляем все значения и приводим к строковому типу, чтобы избежать ошибок при дальнейшем сведении всех результатов в красивую табличку.



```{r}
tsv %>% select(Группа, where(is.numeric)) %>%
  group_by(Группа) %>% 
  summarise(across(where(is.numeric), statistics)) %>%
  pivot_longer(!Группа, names_to = 'Статистика', values_to = 'Значение') %>%
  separate(Статистика, into = c('Переменная', 'Статистика'), sep = '_')
```

## Формирование статистической таблицы для категориальной переменной

```{r}
tsv %>% select(Группа, where(is.factor)) %>%
  mutate(Группа.крови = Группа.крови %>% as.character() %>% replace_na('Нет данных') %>% as.factor()) %>%
  count(Группа, Группа.крови) %>%
  group_by(Группа) %>%
  mutate('Group proportion' = (n/sum(n) * 100) %>% round(4) %>% str_c('%')) %>%
  ungroup() %>%
  mutate('Sample proportion' = (n/sum(n) * 100) %>% round(4) %>% str_c('%'))
```
Для категориальной таблицы достаточно лишь ещё одной ранее неизученной функции count(), которая просто считает количество уникальных сочетаний указанных переменных. Здесь сочетание — группа и группа крови. 

# Печать таблиц with flextable::flextable()

Предназначение пакета flextable — создавать из датафреймов таблицы, которые можно напрямую печатать в html, pdf, использовать в документах Word, PowerPoint.

Существует несколько способов печатать таблицы с помощью этого пакета, однако здесь мы изучим самый простой: связку rmarkdown + flextable. Используя её, достаточно лишь в чанке написать код преобразования заранее подготовленного датафрейма в форматированную таблицу для печати, после чего напечатать rmarkdown-документ. Его результатом будет документ, например, *docx, в котором одна за другой будут напечатаны озаглавленные статистические таблицы, при необходимости снабжённые поясняющим текстом (вспомните уроки по rmarkdown).

*Theme options:*
theme_box(), theme_apa(), theme_alafoli(), theme_booktabs(), theme_zebra(), theme_vanilla() etc


```{r}
tsv %>% select(Группа, where(is.numeric)) %>%
  group_by(Группа) %>% 
  summarise(across(where(is.numeric), statistics)) %>%
  pivot_longer(!Группа, names_to = 'Статистика', values_to = 'Значение') %>%
  separate(Статистика, into = c('Переменная', 'Статистика'), sep = '_') %>%
  flextable::flextable() %>%
  flextable::theme_box()


```

### flextable::merge_h(), flextable::merge_v()

Одни из самых важных функций. Они позволяют склеивать ячейки так, чтобы таблица приобрела читаемый вид. 

Это можно делать как просто указав столбец (в таком случае будут склеены все ячейки с одинаковым текстом), так и более сложным способом, например, указав функцию. 

```{r}
tsv %>% select(Группа, where(is.numeric)) %>%
  group_by(Группа) %>% 
  summarise(across(where(is.numeric), statistics)) %>%
  pivot_longer(!Группа, names_to = 'Статистика', values_to = 'Значение') %>%
  separate(Статистика, into = c('Переменная', 'Статистика'), sep = '_') %>%
  flextable::flextable() %>%
  flextable::theme_box() %>%
  flextable::merge_v(c('Группа', 'Переменная'))
```


```{r}
tibble(
  var1 = c('p-value','0.001'),
  var2 = c('p-value','0.05')
) %>%
  flextable::flextable() %>%
  flextable::theme_box() %>%
  flextable::merge_h(i=1)
```
Имейте в виду, аргумент "i" крайне важен, он указывает строки, в которых нужно склеивать ячейки, иначе может быть так, что склеятся не те строки.

### flextable::align()

```{r}
align(subtable, i = NULL, j = NULL, align = c("left", "center", "right", "justify"), part = "body")

# мы хотим, чтобы текст с SOC был выровнен влево, а PT вправо.

... %>%
  flextable::align(i = ~ str_detect(column_name, 'SOC'), align = 'left') %>%
  flextable::align(i = ~ str_detect(column_name, 'PT'), align = 'right') %>%
  width(width = 2) %>% #ширина столбцов
# еще хотим выделить все SOC жирным шрифтом, а все PT курсивом.
  flextable::bold(i = ~ str_detect(column_name, 'SOC')) %>%
  flextable::italic(i = ~ str_detect(column_name, 'PT'))
```


### flextable::color(), flextable::bg()

В качестве иллюстрации раскрасим сформированный столбец. Это часто полезно, когда надо выделить в таблице, например, все p-value меньше 0.05 или особо высокие средние значения.

Первая функция изменяет цвет текста, вторая же заливает цветом саму ячейку.

```{r}

is_pvalue_sign <- function(x) {
  x <- x %>% str_remove('<') %>% as.numeric()
  return(x < 0.05)
}

tibble(
  p_value = c('<0.001', '0.05', '0.1', '0.38', '0.04') 
) %>%
  flextable::flextable() %>%
  flextable::theme_box() %>%
  flextable::color(i = ~ is_pvalue_sign(p_value), color = 'red') %>%
  flextable::bg(i = ~ is_pvalue_sign(p_value), bg = 'yellow')



```

# colors

[R colors](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf)


# Reading and writing files

1. read.csv() читает csv с запятой в качестве разделителя;
2. read.csv2() читает csv с точкой с запятой в качестве разделителя (кстати, этот же формат отлично читает Excel, сразу разбивая его на столбцы);
3. read.tsv() читает csv со знаком табуляции в качестве разделителя (часто этот формат сохраняют в файле с расширением .txt)


Однако, в каждой функции при этом можно указать параметры sep, quote, dec, которые, соответственно, устанавливают знаки: разделителя, кавычек, десятичного разделителя. 

Дополнительно можно указать параметр header, который говорит функции, является ли первая строка документа заголовком для каждого столбца или нет.

```{r}
#Basic function
read.csv('data.csv', sep = ',', header = TRUE)


```

### readr package
read_delim() allows you to specify the delimiter, quote, and other parameters

```{r}
read_delim('data/raw/data_csv.csv', delim = NULL, quote = '\', skip = 0, n_max = Inf, col_names = TRUE) #general syntax
 
read_delim('data/raw/data_csv.csv', delim = ',', quote = '\', skip = 0, n_max = 10)

write_delim('data/raw/data_csv.csv', delim = ',', na = 'NA')
```

### rds format

rds format is a binary format that is more efficient than csv and xlsx. It is also more secure because it doesn't allow for any data corruption. 

Его особенность в том, что он просто сериализует (переводит в некий общий набор байт) нужный объект. Если это таблица, которую мы, разумеется, предварительно почистили и привели все переменные к нужным типам (а основных типов в базовом случае два: количественный и факторный), то сохранение в формат rds сохраняет и типы. 

Как бонус, в этот формат можно сохранять буквально что угодно: модели, списки, переменные. И потом восстановить это в первозданном виде. 

```{r}
read_rds('data/raw/data.rds')
write_rds(data, 'data/raw/data.rds')
```



```{r}
tsv <- read.csv('https://stepik.org/media/attachments/course/122402/data_tsv.tsv', sep = '\t', header = TRUE)
tsv
```

Functions from readr packag with defined separator and quote

```{r}

read_csv('data/raw/data_csv.csv', skip = 0, n_max = Inf) #разделитель-запятая
read_csv2('data/raw/data_csv2.csv', skip = 0, n_max = Inf) #разделитель-точка с запятой
read_tsv('data/raw/data_tsv.tsv', skip = 0, n_max = Inf) #разделитель-табуляция

```

функции с дополнением 'excel' позволяют меньше опасаться, что при открытии файлов в Excel вместо кириллических (чаще) или иных символов (реже) пользователь увидит нечитаемый набор символов из-за сбоя кодировки.

```{r}
write_csv(data, 'data/raw/data_csv.csv')
write_excel_csv(data, 'data/raw/data_csv.csv')
write_csv2(data, 'data/raw/data_csv2.csv')
write_excel_csv2(data, 'data/raw/data_csv2.csv')
```


```{r}
read_tsv('data/raw/data_tsv.tsv', skip = 0, n_max = Inf)
write_tsv('data/raw/data_tsv.tsv')
```

### readxl package

```{r}
read_excel('data/raw/data_excel.xlsx', sheet = 'data')
write.xlsx(data, 'data_excel.xlsx', colNames = TRUE)
```

### openxlsx package

openxlsx package is a bit more complicated than readxl, but it allows you to read and write xlsx files with a lot of customization options. 
It requires Java.

Аргументы col.names и row.names говорят, нужно ли записывать в файл имена столбцов и имена строк соответственно. По умолчанию оба равны TRUE.

Аргумент append нужен для того, чтобы добавлять новые листы к уже существующей книге. 

```{r}
write.xlsx(data, 'data_excel.xlsx', sheetName = 'data', col.names = TRUE, row.names = TRUE, append = FALSE) # new file
write.xlsx(data, 'data_excel.xlsx', sheetName = 'data_2', col.names = TRUE, row.names = TRUE, append = TRUE) # add new sheet
```

write.xlsx2() функция с цифрой 2 используется преимущественно для того, чтобы быстро записывать крайне большие датафреймы (более, чем 100 тысяч ячеек).

### writexl package

The difference between writexl and openxlsx is that writexl is faster and more efficient. 

```{r}
write_xlsx(data, 'data_excel.xlsx')
```


### haven package

For reading and writing SPSS, Stata, and SAS files

```{r}
read_spss()
read_sas()

write_sas()
write_sav() 
```















