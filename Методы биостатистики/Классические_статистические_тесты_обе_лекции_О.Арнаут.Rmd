---
title: "Bivariate_hypothesis_testing"
author: "Oleg Arnaut"
date: "2024-10-24"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#install.packages('BSDA')

library(tidyverse)
library(ggplot2)
library(BSDA)


```


#Распределения

## Normal Distribution

```{r}

# Загрузка необходимых библиотек
library(ggplot2)

# Создание последовательности значений x
x_values <- seq(-4, 4, by = 0.01)

# Рассчет значений PDF для стандартного нормального распределения
pdf_normal <- dnorm(x_values, mean = 0, sd = 1)

# Создание данных для построения графика PDF и визуализации стандартного нормального распределения
pdf_data <- data.frame(x = x_values, Вероятность = pdf_normal)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x, y = Вероятность)) +
  geom_line(size = 1, color = "blue") +
  labs(title = "PDF стандартного нормального распределения", x = "x", y = "Плотность вероятности") +
  theme_minimal()




```


## Bernoulli Distribution

Распределение Бернулли - это дискретное распределение, которое моделирует случайную переменную, которая принимает только два значения (например, 0 и 1) с заданной вероятностью успеха.

Например, это может быть использовано для моделирования результатов броска монеты, где "успех" может быть определен как выпадение орла (1) и "неудача" как выпадение решки (0).

Или это может быть использовано для моделирования результатов эксперимента, где "успех" может быть определен как наличие некоторого события (1), а "неудача" как его отсутствие (0).
  
```{r}
# Определение вероятности успеха для распределения Бернулли
p <- 0.3

# Создание последовательности возможных значений (0 и 1)
x_values <- c(0, 1)

# Расчет значений PMF для распределения Бернулли
pmf_bernoulli <- c(1 - p, p)

# Создание данных для построения графика PMF и визуализации распределения Бернулли
pmf_data <- data.frame(x = x_values, Вероятность = pmf_bernoulli)

# Создание графика PMF для визуализации распределения Бернулли
ggplot(pmf_data, aes(x = factor(x), y = Вероятность)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", width = 0.5) +
  labs(title = "PMF распределения Бернулли", x = "Исход", y = "Вероятность") +
  theme_minimal()



```



## Binomial Distribution

Биномиаальное распределение - это дискретное распределение, которое моделирует случайную переменную, представляющую собой количество успехов в серии независимых идентичных экспериментов.

Например, это может быть использовано для моделирования количества орлов в серии бросков монеты, где каждый бросок является независимым экспериментом, и вероятность успеха (выпадения орла) одинакова для каждого броска.

```{r}

# Определение параметров биномиального распределения
n <- 30  # Количество попыток
p <- 0.2  # Вероятность успеха в каждой попытке

# Создание последовательности возможных значений для числа успехов
x_values <- 0:n

# Расчет значений PMF для биномиального распределения
pmf_binomial <- dbinom(x_values, size = n, prob = p)

# Создание данных для построения графика PMF и визуализации биномиального распределения
pmf_data <- data.frame(x = x_values, Вероятность = pmf_binomial)

# Создание графика PMF для визуализации биномиального распределения
ggplot(pmf_data, aes(x = factor(x), y = Вероятность)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", width = 0.5) +
  labs(title = "PMF биномиального распределения", x = "Количество успехов", y = "Вероятность") +
  theme_minimal()



```




## Poisson Distribution

Пойссоновское распределение - это дискретное распределение, которое моделирует случайную переменную, представляющую собой количество событий, произошедших за фиксированный период времени или в фиксированном объеме пространства.

```{r}

# Определение средней интенсивности событий для распределения Пуассона
lambda <- 10  # Средняя интенсивность событий

# Создание последовательности возможных значений для количества событий
x_values <- 0:20

# Расчет значений PMF для распределения Пуассона
pmf_poisson <- dpois(x_values, lambda)

# Создание данных для построения графика PMF и визуализации распределения Пуассона
pmf_data <- data.frame(x = x_values, Вероятность = pmf_poisson)

# Создание графика PMF для визуализации распределения Пуассона
ggplot(pmf_data, aes(x = factor(x), y = Вероятность)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", width = 0.5) +
  labs(title = "PMF распределения Пуассона", x = "Количество событий", y = "Вероятность") +
  theme_minimal()




```



## Chi-Squared Distribution

Распределение хи-квадрат - это непрерывное распределение, которое моделирует сумму квадратов независимых стандартных нормальных случайных величин.

Например, это может быть использовано для моделирования суммы квадратов отклонений наблюдаемых значений от ожидаемых значений в хи-квадрат тесте независимости.

```{r}

# Определение степеней свободы для распределения хи-квадрат
df <- 15  # Степени свободы

# Создание последовательности значений x
x_values <- seq(0, 100, by = 0.1)  # Подстройте диапазон и размер шага по мере необходимости

# Расчет значений PDF для распределения хи-квадрат
pdf_chi_squared <- dchisq(x_values, df)

# Создание данных для построения графика PDF и визуализации распределения хи-квадрат
pdf_data <- data.frame(x = x_values, Плотность_вероятности = pdf_chi_squared)

# Создание графика PDF для визуализации распределения хи-квадрат
ggplot(pdf_data, aes(x = x, y = Плотность_вероятности)) +
  geom_line(linewidth = 1, color = "blue") +
  labs(title = "PDF распределения хи-квадрат", x = "x", y = "Плотность вероятности") +
  theme_minimal()




```


## Student's Distribution

```{r}

# Определение степеней свободы для t-распределения
df <- 5  # Степени свободы

# Создание последовательности значений x
x_values <- seq(-3, 3, by = 0.1)  # Подстройте диапазон и размер шага по мере необходимости

# Расчет значений PDF для t-распределения
pdf_t <- dt(x_values, df)

# Создание данных для построения графика PDF и визуализации t-распределения
pdf_data <- data.frame(x = x_values, Плотность_вероятности = pdf_t)

# Создание графика PDF для визуализации t-распределения
ggplot(pdf_data, aes(x = x, y = Плотность_вероятности)) +
  geom_line(size = 1, color = "blue") +
  labs(title = "PDF t-распределения Стьюдента", x = "x", y = "Плотность вероятности") +
  theme_minimal()




```


## Fisher-Snedecor Distribution

```{r}

# Определение степеней свободы для F-распределения
df1 <- 100  # Число степеней свободы в числителе
df2 <- 100  # Число степеней свободы в знаменателе

# Создание последовательности значений x
x_values <- seq(0.01, 5, by = 0.01)  # Подстройте диапазон и размер шага по мере необходимости

# Рассчет значений PDF для F-распределения
pdf_fisher <- df(x_values, df1, df2)

# Создание данных для построения графика
pdf_data <- data.frame(x = x_values, Вероятность = pdf_fisher)

# Создание графика PDF для визуализации F-распределения
ggplot(pdf_data, aes(x = x, y = Вероятность)) +
  geom_line(size = 1, color = "blue") +
  labs(title = "PDF распределения Фишера-Снедекора (F)", x = "x", y = "Плотность вероятности") +
  theme_minimal()
```



# Параметрические критерии

*Асимптотические тесты*
- основаны на свойствах ЦПТ
- используются для больших выборок (если выборка большая, то можно смело ипользовать асимптотический тест)
- если есть мат. ожидание и дисперсия, то можно использовать асимптотический тест (z-критерий)


*Точные тесты*
- используются для маленьких выборок
- точные критерии подстраиваются под нашу выборку: они основываются на точных распределениях выборочных статистик (например, t-распределение)
- могут быть более надежными, так как учитывают все возможные комбинации данных

## Гипотезы о средних

### Z-критерий для среднего - асимптотический тест

z-критерий для среднего - это статистический тест, который используется для проверки гипотезы о среднем значении генеральной совокупности на основе выборки.

z-критерий распределяется нормально, соответственно мы используем квантили стандартного нормального распределения для определения критических значений.

```{r}

#?quantile

observed=-4 # наблюдаемое значение z

# Создание последовательности значений x
x_values <- seq(-4, 4, by = 0.01)

# Расчет значений Плотности Вероятности (PDF) для стандартного нормального распределения
pdf_normal <- dnorm(x_values, mean = 0, sd = 1)

# Квантили
# quantiles <- c(0.025, 0.975) # двусторонний ДИ
quantiles <- c(0.05, 1) # левосторонний ДИ - перенесли влево 0.025 

quantile_values <- qnorm(quantiles, mean = 0, sd = 1)

# Создание данных для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_normal)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x)) +
  geom_line(aes(y = Probability), linewidth = 1, color = "black", linetype = "solid") +
  geom_vline(xintercept = quantile_values, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = observed, linewidth = 2, linetype = "dashed", color = "red") +
  annotate("text", x = quantile_values[1]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], quantile_values[1]), hjust = 0, angle = 90) +
  annotate("text", x = quantile_values[2]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], quantile_values[2]), hjust = 0, angle = 90) +
  annotate("text", x = observed-0.15, y = 0.2, label = 'observed', hjust = 0, angle = 90)+
  labs(title = "PDF стандартного нормального распределения", x = "x", y = "Плотность вероятности")
  
```


### t-критерий для среднего - точный тест

t-статистика является точным тестом, в отличие от z-статистики, когда стандартное отклонение генеральной совокупности неизвестно и оценивается по выборке.

Вводим понятие степеней свободы (df), которое зависит от размера выборки и используется для определения квантилей t-распределения.

t-статистика распределяется как t-распределение с df степенями свободы. Так как оно чуть отличается от нормального распределения, мы используем квантили t-распределения для определения критических значений.(то есть критические значения будут немного другими)

*Пример*

Мы проводим экспериментальное исследование, в котором мы хотим проверить уровень гликолизировааного гемоглобина у пациентов с СД2 после нового лечения.

Нам известно, что в общей популяции пациентов с СД2 уровень гликолизированного гемоглобина равен 10%. Мы хотим проверить, изменился ли уровень гликолизированного гемоглобина после нового лечения.

То есть у нас 1 группа, которую мы сравниваем с предполагаемой средней величиной в генеральной совокупности.


```{r}
# данные выборки

mean_true = 10

n = 100
mean_sample = 8
sd_sample = 5

t_stat = (mean_sample - mean_true) / (sd_sample / sqrt(n))
t_stat

# our observed t-statistic
observed <- t_stat

```



```{r}

#?quantile

# observed=-4 # это мы уж посчитали t-критерий по нашим данным ()

# NEW for t-distribution
# Define the degrees of freedom for the t-distribution
df <- n - 1  # Degrees of freedom

# Create a sequence of x values
x_values <- seq(-5, 5, by = 0.01)  # Adjust the range and step size as needed

# Calculate the PDF values for the t-distribution
pdf_t <- dt(x_values, df)

# Квантили
quantiles <- c(0.05, 1) # левосторонний ДИ

#quantile_values <- qnorm(quantiles, mean = 0, sd = 1)

t_critical_low <- qt(quantiles[1], df = df)
t_critical_up <-  qt(quantiles[2], df = df)

# Create a data frame for plotting
pdf_data <- data.frame(x = x_values, Probability = pdf_t)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x)) +
  geom_line(aes(y = Probability), linewidth = 1, color = "black", linetype = "solid") +
  geom_vline(xintercept = t_critical_low, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = t_critical_up, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = observed, linewidth = 2, linetype = "dashed", color = "red") +
  annotate("text", x = t_critical_low-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], t_critical_low), hjust = 0, angle = 90) +
  annotate("text", x = t_critical_up-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], t_critical_up), hjust = 0, angle = 90) +
  annotate("text", x = observed-0.15, y = 0.2, label = 'observed', hjust = 0, angle = 90)+
  annotate("text", x = 2.5, y = 0.4, label = sprintf("df(%.0f)", df), hjust = 0)+
  labs(title = "PDF распределения Стьюдента", x = "x", y = "Плотность вероятности")


```
Посчитанный t-критерий вышел за критическую область, что означает, что мы можем отклонить нулевую гипотезу о равенстве средних в генеральной совокупности и выборке. - препарат работает.

### Реализация в R

```{r}

library(BSDA)

# Тест Z для одной выборки

# Данные (замените их своими данными)
sample_data_z <- c(23, 25, 27, 21, 24, 26, 22, 28, 25, 27)

# Гипотеза о среднем значении в генеральной совокупности
population_mean_z <- 25

# Выполнить тест Z
z_test_result <- BSDA::z.test(sample_data_z, mu = population_mean_z, sigma.x =sd(sample_data_z))

# Вывести результат
print("Тест Z для одной выборки:")
print(z_test_result)


# Тест t для одной выборки

# Данные (замените их своими данными)
sample_data_t <- c(23, 25, 27, 21, 24, 26, 22, 28, 25, 27)

# Гипотеза о среднем значении в генеральной совокупности
population_mean_t <- 25

# Выполнить тест t
t_test_result <- t.test(sample_data_t, mu = population_mean_t)

# Вывести результат
print("Тест t для одной выборки:")
print(t_test_result)

?t.test


```




## Гипотезы о разнице средних

### Z-критерий для разности средних. Выборки независимые

```{r}

# Загрузка необходимого пакета ggplot2
library(ggplot2)

#?quantile

observed=3

# Создание последовательности значений x
x_values <- seq(-4, 4, by = 0.01)

# Расчет значений Плотности Вероятности (PDF) для стандартного нормального распределения
pdf_normal <- dnorm(x_values, mean = 0, sd = 1)

# Квантили
quantiles <- c(0.025, 0.975)

quantile_values <- qnorm(quantiles, mean = 0, sd = 1)

# Создание данных для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_normal)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x)) +
  geom_line(aes(y = Probability), linewidth = 1, color = "black", linetype = "solid") +
  geom_vline(xintercept = quantile_values, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = observed, linewidth = 2, linetype = "dashed", color = "red") +
  annotate("text", x = quantile_values[1]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], quantile_values[1]), hjust = 0, angle = 90) +
  annotate("text", x = quantile_values[2]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], quantile_values[2]), hjust = 0, angle = 90) +
  annotate("text", x = observed-0.15, y = 0.2, label = 'observed', hjust = 0, angle = 90)+
  labs(title = "PDF стандартного нормального распределения", x = "x", y = "Плотность вероятности")

```



### t-критерий для разности средних. Выборки независимые (и зависимые - но здесь без примера)

t-test по методу Уэлча - когда мы не знаем дисперсию в популяции и у нас есть только дисперсия в выборке

*Пример*

Мы ииследуем влияние нового препарата на основной метаболизм крыс (ОМК). У нас есть 2 группы крыс - контрольная и экспериментальная. 

Мы хотим проверить, есть ли статистически значимое различие в среднем метаболизме между этими двумя группами.

Известно, что размер выборки в обоих группах равен 10.
ОМК в контроле = 8.2 и стандартное отклонение = 6
ОМК в эксперименте = 10 и стандартное отклонение = 4

Для такого случая мы можем использовать тест Уэлча (**t-test по методу Уэлча**), так как истинные дисперсии нам неизвестно(то есть почти всегда при сравнении средних групп мы будем использовать t-test по методу Уэлча).

В классическом t-test мы предполагаем, что дисперсии в обеих группах равны. Однако в реальной жизни это может быть не так - мы не знаем. Поэтому мы используем t-test по методу Уэлча, который не предполагает равенства дисперсий.

(Есть тесты для проверки равенства дисперсий - например, тест Левена, тест Бартлетта, но мы там тоже можем совершить ошибку)

В классическом t-test мы бы считали количество степеней свободы для построения t-распределения как n1 + n2 - 2, где n1 и n2 - размеры выборок.

В тесте Уэлча степени свободы рассчитываются по более сложной формуле, которая учитывает дисперсии в обеих группах.

```{r}
## Степени свободы для теста Welch - t-test по методу Уэлча 

sd_x = 6
nx   = 10 # размер выборки x
sd_y = 4
ny   = 10 # размер выборки y

# Степени свободы (Welch-Satterthwaite)

numerator <- ((sd_x^2 / nx) + (sd_y^2 / ny))^2
denominator <- (sd_x^4 / (nx^2 * (nx - 1))) + (sd_y^4 / (ny^2 * (ny - 1)))

df <- numerator / denominator

df

```
H0: Средний уровень ОМК в контроле равен среднему уровню ОМК в эксперименте
H1: Средний уровень ОМК в контроле не равен среднему уровню ОМК в эксперименте

```{r}

mean_x = 8.2 # mean ОМК в контроле
mean_y = 10 # mean ОМК в эксперименте

# t test
# full formula
t_test <- (mean_x - mean_y) / sqrt((sd_x^2 / nx) + (sd_y^2 / ny))
t_test

# знак t_test непринципиален, так как у нас двухсторонняя гипотеза
# при односторонней гипотезе нужно смотреть на знак


```

```{r}
#?quantile

observed = t_test # выше посчитали t-критерий по нашим данным с помощью формулы для разницы средних

# Определение степеней свободы для t-распределения
df # Степени свободы по методу Уэлча

# Создание последовательности значений x
x_values <- seq(-4, 4, by = 0.01)  # Подстройте диапазон и размер шага по мере необходимости

# Рассчет значений PDF для t-распределения
pdf_t <- dt(x_values, df)


# Квантили
quantiles <- c(0.025, 0.975)

#for z-test : quantile_values <- qnorm(quantiles, mean = 0, sd = 1)

# qt! - квантили t-распределения (в отличие от z-теста)
t_critical_low <- qt(quantiles[1], df = df)
t_critical_up <-  qt(quantiles[2], df = df)

# Create a data frame for plotting
pdf_data <- data.frame(x = x_values, Probability = pdf_t)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x)) +
  geom_line(aes(y = Probability), linewidth = 1, color = "black", linetype = "solid") +
  geom_vline(xintercept = t_critical_low, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = t_critical_up, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = observed, linewidth = 2, linetype = "dashed", color = "red") +
  annotate("text", x = t_critical_low-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], t_critical_low), hjust = 0, angle = 90) +
  annotate("text", x = t_critical_up-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], t_critical_up), hjust = 0, angle = 90) +
  annotate("text", x = observed-0.15, y = 0.2, label = 'observed', hjust = 0, angle = 90)+
  annotate("text", x = 2.5, y = 0.6, label = sprintf("df(%.0f)", df), hjust = 0)+
  labs(title = "PDF распределения Стьюдента", x = "x", y = "Плотность вероятности")


```
Так как посчитанный нами t-критерий попал в область допустимых значений для t-распределения нулевой гипотезы, мы не можем отвергнуть нулевую гипотезу о равенстве средних. - препарат не действует на ОМК.

### Реализация в R
 
```{r}

library(BSDA)


# Sample data for group A and group B
group_A <- c(15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25)
group_A <- group_A + 2
group_B <- c(10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30)


z_test <- BSDA::z.test(x = group_A, y = group_B, alternative = "two.sided", sigma.x =sd(group_A), sigma.y = sd(group_B))

# Perform a t-test for the means of two independent samples (assuming equal variances)
t_test <- t.test(group_B, group_A, var.equal = TRUE)


# Perform a t-test for the means of two independent samples (assuming unequal variances)
t_test_Welch <- t.test(group_B, group_A, var.equal = FALSE)


print(t_test_Welch)
print(t_test)
print(z_test)

?t.test


```


## Гипотезы о долях




### Z-критерий для доли 

Исследование эффективности нового метода обучения для улучшения памяти студентов.

Группе студенто предложили новый метод для улучшения памяти. После проведения обучения и тестирования, студентов делят на двк категории: те, кто успешно запомнил информацию (успех) и те, кто не показал улучшения (неуспех) .

Исследователь хочет проверить, если доля студентов с улучшенной памятью после нового метода обучения больше целевой доли 50% (р0)

p0 = 50%

Н0: p = p0 - доля успеха в генеральной совокупности равна p0
H1: p > p0 - доля успеха в генеральной совокупности не равна p0 (правосторонняя гипотеза)


```{r}
p_true = 0.5
p_sample = 0.7
n = 100

z_stat = (p_sample - p_true) / sqrt(p_true * (1 - p_true) / n)
z_stat
```


```{r}
#?quantile

observed <- z_stat

# Создание последовательности значений x
x_values <- seq(-4, 4, by = 0.01)

# Расчет значений Плотности Вероятности (PDF) для стандартного нормального распределения
pdf_normal <- dnorm(x_values, mean = 0, sd = 1) # dnorm - как и раньше

# Квантили
quantiles <- c(0, 0.95)
# qnorm - как и раньше
quantile_values <- qnorm(quantiles, mean = 0, sd = 1)

# Создание данных для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_normal)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x)) +
  geom_line(aes(y = Probability), linewidth = 1, color = "black", linetype = "solid") +
  geom_vline(xintercept = quantile_values, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = observed, linewidth = 2, linetype = "dashed", color = "red") +
  annotate("text", x = quantile_values[1]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], quantile_values[1]), hjust = 0, angle = 90) +
  annotate("text", x = quantile_values[2]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], quantile_values[2]), hjust = 0, angle = 90) +
  annotate("text", x = observed-0.15, y = 0.2, label = 'observed', hjust = 0, angle = 90)+
  labs(title = "PDF стандартного нормального распределения", x = "x", y = "Плотность вероятности")

```
Нулевую гипотезу о равенстве доли успеха в генеральной совокупности целевой доли 50% мы можем отвергнуть, так как наш z-статистика попала в критическую область.

### Точный критерий для доли 

Здесь используем распределение Бернулли - это дискретное распределение, которое моделирует случайную величину, которая принимает значение 1 с вероятностью p и 0 с вероятностью 1-p.

```{r}

# Загрузка необходимых библиотек
library(ggplot2)

# Определение параметров биномиального распределения
n <- 100   # Количество испытаний
p <- 0.5   # Вероятность успеха в каждом испытании (истина)

наблюдаемые = 70

# Создание последовательности возможных значений числа успехов
x_values <- 1:n

# Расчет значений ПФР (вероятности массовой функции) для биномиального распределения
# dbinom! (в z-тесте мы использовали dnorm)
pmf_binomial <- dbinom(x_values, size = n, prob = p)

# Создание фрейма данных для построения
pmf_data <- data.frame(x = x_values, Вероятность = pmf_binomial)

# Квантили
квантили <- c(0, 0.95)

# Расчет критических значений (квантилей)
critical_value_left <- qbinom(квантили[1], size = n, prob = p)
critical_value_right <- qbinom(квантили[2], size = n, prob = p)

# Создание графика ПФР для визуализации биномиального распределения
ggplot(pmf_data, aes(x = factor(x), y = Вероятность)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", width = 0.5) +
  labs(title = "PMF биномиального распределения", x = "Количество успехов", y = "Вероятность") +
  theme_minimal() +
  geom_vline(xintercept = critical_value_left, linetype = "solid", color = "blue", size = 2) +
  geom_vline(xintercept = critical_value_right, linetype = "solid", color = "blue", size = 2) +
  geom_vline(xintercept = наблюдаемые, size = 2, linetype = "dashed", color = "red") +
  annotate("text", x = critical_value_left + n/50, y = max(pmf_binomial), label = sprintf("Q(%.3f)=%.2f", квантили[1], critical_value_left), color = "black", hjust = 1, angle = 90) +
  annotate("text", x = critical_value_right + n/50, y = max(pmf_binomial), label = sprintf("Q(%.3f)=%.2f", квантили[2], critical_value_right), color = "black", hjust = 1, angle = 90) +
  annotate("text", x = наблюдаемые - n/50, y = max(pmf_binomial), label = 'наблюдаемое', hjust = 1, angle = 90)


```

### Реализация в R


```{r}


library(BSDA)

# Aсимптотический тест
# Исходные данные
n <- 100  # Общее количество попыток
x <- 70   # Количество успешных исходов

# Значение нулевой гипотезы (обычно 0.5 для двустороннего теста)
p0 <- 0.5

# Создание бинарной выборки
выборка <- c(rep(1, x), rep(0, n - x))

# Перемешивание выборки для случайного порядка
выборка <- sample(выборка)

# Рассчет стандартного отклонения
stdev <- sqrt(p0*(1-p0))

# Выполнение z-теста
результат_z_теста <- BSDA::z.test(выборка, mu = p0, alternative = "two.sided", sigma.x = stdev)

# Вывод результатов теста
print(результат_z_теста)

# Точный тест
?binom.test()

# Количество попыток (размер выборки)
n <- 100

# Ожидаемая доля успешных исходов
ожидаемая_доля <- 0.5

# Количество успешных исходов (наблюдаемых)
наблюдаемые_успехи <- 70

# Выполнение биномиального теста
результат_бином_теста <- binom.test(наблюдаемые_успехи, n, p = ожидаемая_доля, alternative = "two.sided")

# Вывод результатов теста
print(результат_бином_теста)



```


## Гипотезы о разнице долей

### Z-критерий для разности долей для независимых выборок выборок

P0: p1 = p2 - доли в генеральной совокупности равны
H1: p1 != p2 - доли в генеральной совокупности не равны

```{r}
p1 = 0.2
n1 = 100
p2 = 0.4
n2 = 100

# p - объединенная доля
p = (p1 * n1 + p2 * n2) / (n1 + n2)
p

z_stat = (p1 - p2) / sqrt(p * (1 - p) * (1/n1 + 1/n2)) # ~ N(0, 1)
z_stat
```


```{r}
#?quantile

observed=z_stat

# Создание последовательности значений x
x_values <- seq(-4, 4, by = 0.01)

# Расчет значений Плотности Вероятности (PDF) для стандартного нормального распределения
pdf_normal <- dnorm(x_values, mean = 0, sd = 1)

# Квантили
quantiles <- c(0.025, 0.975)

quantile_values <- qnorm(quantiles, mean = 0, sd = 1)

# Создание данных для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_normal)

# Создание графика PDF для визуализации стандартного нормального распределения
ggplot(pdf_data, aes(x = x)) +
  geom_line(aes(y = Probability), linewidth = 1, color = "black", linetype = "solid") +
  geom_vline(xintercept = quantile_values, linewidth = 2, linetype = "solid", color = "blue") +
  geom_vline(xintercept = observed, linewidth = 2, linetype = "dashed", color = "red") +
  annotate("text", x = quantile_values[1]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], quantile_values[1]), hjust = 0, angle = 90) +
  annotate("text", x = quantile_values[2]-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], quantile_values[2]), hjust = 0, angle = 90) +
  annotate("text", x = observed-0.15, y = 0.2, label = 'observed', hjust = 0, angle = 90)+
  labs(title = "PDF стандартного нормального распределения", x = "x", y = "Плотность вероятности")




```
Отвергаем нулевую гипотезу о равенстве долей в генеральной совокупности.

### Точный тест для разности долей для независимых выборок выборок

Используем биноминальное распределение вместо нормального


### Реализация в R


```{r}

# Aсимптотический тест для независимых выборок

# # Исходные данные для выборки 1
# n1 <- 100  # Общее количество попыток
# x <- 20   # Количество успешных исходов
# 
# # Исходные данные для выборки 2
# n2 <- 100  # Общее количество попыток
# y <- 40   # Количество успешных исходов
# 
# # Расчет доли успешных исходов в выборке 1
# p1 <- x / n1
# 
# # Расчет доли успешных исходов в выборке 2
# p2 <- y / n2
# 
# # Расчет объединенной доли успешных исходов
# P <- (x + y) / (n1 + n2)
# 
# # Расчет стандартной ошибки
# SQ <- P * (1 - P) * (1/n1 + 1/n2)
# 
# # Выполнение z-теста
# z_test_result <- (p1 - p2) / sqrt(SQ)
# 
# # Вывод результата теста
# print(z_test_result)

##################################################################


# Функция для проведения z-теста для двух независимых долей
performTwoProportionZTest <- function(n1, x, n2, y) {
  # Расчет долей успешных исходов в выборках
  p1 <- x / n1
  p2 <- y / n2

  # Расчет объединенной доли успешных исходов
  P <- (x + y) / (n1 + n2)

  # Расчет стандартной ошибки
  SQ <- P * (1 - P) * (1/n1 + 1/n2)

  # Выполнение z-теста
  z_test_result <- (p1 - p2) / sqrt(SQ)

  return(z_test_result)
}

# Использование функции:
n1 <- 100  # Общее количество попыток для выборки 1
x <- 20   # Количество успешных исходов для выборки 1

n2 <- 100  # Общее количество попыток для выборки 2
y <- 40   # Количество успешных исходов для выборки 2

z_test_result <- performTwoProportionZTest(n1, x, n2, y)
print(z_test_result)




```



### Z-критерий для разности долей для зависимых выборок

Н0: p1 = p2 - доля пациентов, которые показала улучшение в результате лечения, равны
Н1: р1 < p2 - доля пациентов, которые показали улучшение в результате лечения, увеличилась

```{r}

```



## Эмпирическое правило для биноминального распределения (критерий для использования асимптотических тестов)

Какой тест испольщовать - точный или асимптотический?

Для каждой группы посчитать количество успехов и неуспехов. Если количество успехов и неуспехов в каждой группе больше 5, то можно использовать асимптотический тест. Если меньше - то точный.

n * p >= 5 - количество успехов
n * (1 - p) >= 5 - количество неуспехов



# Гипотезы о дисперсии


### Chi squared – критерий для дисперсии (точный)


```{r}

# Определение степеней свободы для распределения хи-квадрат
df <- 4  # Подстраивайте степени свободы по мере необходимости

# Создание последовательности значений x
x_values <- seq(0.01, 30, by = 0.01)  # Подстраивайте диапазон и шаг по мере необходимости

# Расчет значений PDF для распределения хи-квадрат
pdf_chi_squared <- dchisq(x_values, df)

# Квантили
quantiles <- c(0.25, 0.975)

# Расчет критических значений для распределения хи-квадрат
critical_value_lower <- qchisq(quantiles[1], df)
critical_value_upper <- qchisq(quantiles[2], df)

# Расчет наблюдаемого значения хи-квадрат (замените на ваше фактическое наблюдаемое значение)
observed_chi_squared <- 14.4  # Замените на ваше реальное наблюдаемое значение

# Создание data frame для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_chi_squared)

# Создание графика PDF для визуализации распределения хи-квадрат
ggplot(pdf_data, aes(x = x, y = Probability)) +
  geom_line(size = 1, color = "black") +
  labs(title = "PDF распределения хи-квадрат", x = "x", y = "Плотность вероятности") +
  theme_minimal() +
  geom_vline(xintercept = c(critical_value_lower, critical_value_upper, observed_chi_squared),
             linetype = c("solid", "solid", "dashed"),
             color = c("blue", "blue", "red"),
             size = c(2, 2, 2)) +
  annotate("text", x = critical_value_lower - 0.5, y = 0.1, label = sprintf("Q(%.3f)=%.2f", quantiles[1], critical_value_lower), hjust = 1, angle = 90) +
  annotate("text", x = critical_value_upper - 0.5, y = 0.1, label = sprintf("Q(%.3f)=%.2f", quantiles[2], critical_value_upper), hjust = 1, angle = 90) +
  annotate("text", x = observed_chi_squared - 0.5, y = 0.1, label = 'наблюдаемое', hjust = 1, angle = 90) +
  annotate("text", x = critical_value_upper + 5, y = 0.1, label = sprintf("df = %.0f", df), hjust = 1)


```


### F критерий для разницы дисперсий (точный)

H0: дисперсии в группах равны
H1: дисперсии не равны


Лекция 2 начало


#### Тест Фишера (F-test) для отношения дисперсий vs t-test 

Предположим, мы проводим исследование, в котором измерям уровень тиреоидных гормонов в контрольной и экспериментальной группе. 

Нас интересует, есть ли разница в дисперсиях этих измерений между группами.

Например потому что на основании сравнения средних значений мы не можем отвергнуть нулевую гипотезу о равенстве средних, но при этом дисперсии могут быть разными - то есть в группах могут быть разные разбросы значений - и это может быть важно.


```{r}

# Наборы данных для группы A и группы B
group_A <- c(15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25)
group_B <- c(10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30)

#?var.test

# Выполнение F-теста на отношения дисперсий
результат_F_теста <- var.test(group_A, group_B)

# Вывод результатов F-теста 
cat("Результат F-теста (отношения дисперсий):\n")
print(результат_F_теста)

# Выполнение двухвыборочного t-теста для средних значений двух независимых выборок (предполагается неравенство дисперсий)
результат_t_теста <- t.test(group_A, group_B, var.equal = FALSE) #var.equal = FALSE - метод Уэлча

# Вывод результатов t-теста
cat("\nРезультат t-теста (равенство средних):\n")
print(результат_t_теста)


```

На основании t-теста мы не можем отвергнуть нулевую гипотезу (p = 1) - средние в группе  одинаковые. 

Однако, на основании F-теста мы можем отвергнуть нулевую гипотезу о равенстве дисперсий в группах (p = 0.05).

Теперь визуализируем результаты F-теста.

```{r}

observed_f_value <- результат_F_теста$statistic  # реальное наблюдаемое значение F-статистики

# Определение параметров степеней свободы для F-распределения

df1 <-length(group_A) - 1   # Степени свободы числителя - 11-1
df2 <- length(group_B) - 1  # Степени свободы знаменателя

# Создание последовательности значений x
x_values <- seq(0.01, 5, by = 0.01)  # Подстраивайте диапазон и шаг по мере необходимости

# Тест Фишера - точный, используем F-распределение

# Расчет значений PDF для F-распределения
pdf_fisher <- df(x_values, df1, df2)

# Определение уровня значимости (альфа) для критических значений
quantiles <- c(0.05, 1)  # тест может быть как двухсторонним, так и односторонним 

# Расчет критических значений для F-распределения
# qf - квантиль F-распределения
critical_value_lower <- qf(quantiles[1], df1, df2)
critical_value_upper <- qf(quantiles[2], df1, df2)

# Создание data frame для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_fisher)

# Создание графика PDF для визуализации F-распределения
ggplot(pdf_data, aes(x = x, y = Probability)) +
  geom_line(size = 1, color = "black") +
  labs(title = "PDF F-распределения Фишера-Снедекора", x = "x", y = "Плотность вероятности") +
  theme_minimal() +
  geom_vline(xintercept = c(critical_value_lower, critical_value_upper, observed_f_value),
             linetype = c("solid", "solid", "dashed"),
             color = c("blue", "blue", "red"),
             linewidth = c(2, 2, 2)) +
  annotate("text", x = critical_value_lower-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[1], critical_value_lower), hjust = 0, angle = 90) +
  annotate("text", x = critical_value_upper-0.15, y = 0.2, label = sprintf("Q(%.3f)=%.2f", quantiles[2], critical_value_upper), hjust = 0, angle = 90) +
  annotate("text", x = observed_f_value-0.15, y = 0.2, label = 'наблюдаемое', hjust = 0, angle = 90) +
  annotate("text", x = 4, y = 0.6, label = sprintf("df1=%.0f, df2=%.0f", df1, df2), hjust = 0)

```




Можем отвергнуть нулевую гипотезу о равенстве дисперсий в группах, так как наблюдаемое значение F-статистики (красная пунктирная линия) превышает критическое значение F-статистики (синие линии) при уровне значимости 0.05.

# Непараметрические тесты

## Тест Манна-Уитни-Уилкоксона (вероятностное доминирование)

```{r mw_1}

#?wilcox.test()

n <- 30 # 30 наблюдений в каждой группе

# Среднии значения в группах

t1 <- 1 # Средняя продолжительность болезни в группе 1
t2 <- 1 # Средняя продолжительность болезни в группе 2

# генерируем случайные выборки из экспоненциального распределения со средними значениями t1 и t2
sample_1 <- sort( round(rexp(n, 1/t1),2) )
sample_2 <- sort( round(rexp(n, 1/t2),2) )

df1 <- data.frame(n1 = 1:n,
                  d1  = sort(sample_1)) 

df2 <- data.frame(n2 = 1:n,
                  d2  = sort(sample_2))

df <- merge(df1, df2) %>% 
  mutate(rez = case_when(
    # сравниваем 2 группы
    d1 > d2 ~ +1, 
    d1 < d2 ~ -1,
    TRUE ~ 0)) %>% 
  dplyr::select(-c("d1", "d2")) %>% 
  pivot_wider(names_from = n2, values_from = rez) %>% 
  tibble::column_to_rownames('n1')

#визуализируем результаты теста Манна-Уитни-Уилкоксона
#всего квадратиков 30 на 30

# красный квадрат - победа группы 1
# синий квадрат - победа группы 2
# желтые - равные значения

# ось У - значения в группе 1
# ось Х - значения в группе 2

pheatmap::pheatmap(df,
                   cluster_cols = FALSE,
                   cluster_rows = FALSE)

```



## Критерий Chi squared


Н0: распределение признака в популяции соответствует гипотетическому (ожидаемые и наблюдаемые частоты совпадают) - нет статистически значимой ассоциации между признаками

Н1: распределение признака в популяции не соответствует гипотетическому (ожидаемые и наблюдаемые частоты различаются) - есть статистически значимая ассоциация между признаками

```{r}

# Расчет наблюдаемого значения хи-квадрат (замените на ваше фактическое наблюдаемое значение)
observed_chi_squared <- 5.9  # Замените на ваше реальное наблюдаемое значение

# Определение степеней свободы для распределения хи-квадрат
df <- 1  # Подстраивайте степени свободы по мере необходимости

# Создание последовательности значений x
x_values <- seq(0.01, 10, by = 0.01)  # Подстраивайте диапазон и шаг по мере необходимости

# Расчет значений PDF для распределения хи-квадрат
pdf_chi_squared <- dchisq(x_values, df)

# Квантили - критические значения - правосторонний тест
quantiles <- c(0, 0.95)

# Расчет критических значений для распределения хи-квадрат
critical_value_lower <- qchisq(quantiles[1], df) # 0 quantile
critical_value_upper <- qchisq(quantiles[2], df) # 95



# Создание data frame для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_chi_squared)

# Создание графика PDF для визуализации распределения хи-квадрат
ggplot(pdf_data, aes(x = x, y = Probability)) +
  geom_line(size = 1, color = "black") +
  labs(title = "PDF распределения хи-квадрат", x = "x", y = "Плотность вероятности") +
  theme_minimal() +
  geom_vline(xintercept = c(critical_value_lower, critical_value_upper, observed_chi_squared),
             linetype = c("solid", "solid", "dashed"),
             color = c("blue", "blue", "red"),
             size = c(2, 2, 2)) +
  annotate("text", x = critical_value_lower - 0.5, y = 0.1, label = sprintf("Q(%.3f)=%.2f", quantiles[1], critical_value_lower), hjust = 0, angle = 90) +
  annotate("text", x = critical_value_upper - 0.5, y = 0.1, label = sprintf("Q(%.3f)=%.2f", quantiles[2], critical_value_upper), hjust = 0, angle = 90) +
  annotate("text", x = observed_chi_squared - 0.5, y = 0.1, label = 'наблюдаемое', hjust = 0, angle = 90) +
  annotate("text", x = critical_value_upper - 1, y = 0.5, label = sprintf("df = %.0f", df), hjust = 0)


```



Посчитанные критические значения для хи-квадрат распределения (0,95 квантили - синии линии) и наблюдаемое значение хи-квадрат статистики, посчитанные по реальным данным (красная пунктирная линия) визуализированы на графике.

Отвергаем нулевую гипотезу, так как наблюдаемое значение хи-квадрат статистики превышает критическое значение хи-квадрат статистики при уровне значимости 0.05.


```{r}

# Создание таблицы сопряженности (замените своими данными)
m <- matrix(c(100, 80, 200, 100), nrow = 2)
rownames(m) <- c("Группа A", "Группа В")
colnames(m) <- c("Болен", "Здоров")

print(m)

# Проведение теста хи-квадрат для ассоциации
chi_result <- chisq.test(m)

# Извлечение стандартизированных остатков
residuals <- chi_result$residuals

cat("\nСтандартизированные остатки:\n")
print(residuals)

```
## chisq.test Monte Carlo

Our sample - есть значения 5

```{r}


x <- matrix(c(5, 1, 1, 4), ncol=2)
rownames(x) <- c("Group A", "Group B")
colnames(x) <- c("Outcome 1", "Outcome 2")

# тест хи-квадрат
print(chisq.test(x))   



```
В случае если есть ячейки с ожидаемым значением <1 и более 20% ячеек с значениями <5 можно использовать метод Монте-Карло

Такие ячейки могут быть проблемой для точности теста хи-квадрат.

Почему?

хи-квадрат основывается на предположении, что отклонения наблюдаемых частот от ожидаемых частот имеют нормальное распределение. А случаи, когда есть ожидаемые значения <1 или более 20% ячеек с значениями <5 - то такое распределение смещено и результаты теста становятся менее точными.


В таких ситуациях можно использовать метод Монте-Карло для проведения теста хи-квадрат. Так как симуляции не требуют предположения о нормальности распределения.

```{r}

# тест хи-квадрат
print(chisq.test(x, simulate.p.value = TRUE, B = 10000)) # 10000 simulations

```

Монте-Карло в целом дает более точные результаты.


## Точный критерий Фишера

Не то же самое, что и F-тест Фишера для дисперсий!

H0: нет ассоциации между признаками
H1: есть ассоциация между признаками

Точный критерий Фишера по сути похож на тест хи-квадрат, но он используется для маленьких выборок и когда есть ожидаемые значения <5.



## goodness of fit (критерий соответствия), Хи-квадрат критерий согласия 

H0: Наблюдаемые частоты соответствуют ожидаемым частотам
H1: Наблюдаемые частоты не соответствуют ожидаемым частотам

Одинаково для распространены разные виды осложнения среди пациентов после операции?

8 инфекционных, 12 кровотечений, 10 осложнений с дыханием, 9 осложнений с сердцем, 16 другие

H0: Распределение частоты осложнений одинаково
H1: Распределение частоты осложнений различно

```{r}

# Наблюдаемые частоты
observed <- c(8, 12, 10, 9, 16)

# 55 всего наблюдений - 5 типов осложнений - тогда в каждой клеточке ожидаемое значение 11

# Проведение теста хи-квадрат - 
chi <- chisq.test(observed, p = c(0.2, 0.2, 0.2, 0.2, 0.2))

# Вывод результатов
print(chi)

# Интерпретация результатов
alpha <- 0.05
if (chi$p.value < alpha) {
  cat("Отклонить нулевую гипотезу\n")
} else {
  cat("Не удалось отклонить нулевую гипотезу\n")
}

chi$residuals


```


Визуализируем

```{r}
# Расчет наблюдаемого значения хи-квадрат (замените на ваше фактическое наблюдаемое значение)
observed_chi_squared <- chi$statistic  # из предыдущего чанка

df <- 5 - 1   # тоже из предыдущего чанка

# Создание последовательности значений x
x_values <- seq(0.01, 10, by = 0.01)  # Подстраивайте диапазон и шаг по мере необходимости

# Расчет значений PDF для распределения хи-квадрат
pdf_chi_squared <- dchisq(x_values, df)

# Квантили - критические значения - правосторонний тест
quantiles <- c(0, 0.95)

# Расчет критических значений для распределения хи-квадрат
critical_value_lower <- qchisq(quantiles[1], df) # 0 quantile
critical_value_upper <- qchisq(quantiles[2], df) # 95



# Создание data frame для построения графика
pdf_data <- data.frame(x = x_values, Probability = pdf_chi_squared)

# Создание графика PDF для визуализации распределения хи-квадрат
ggplot(pdf_data, aes(x = x, y = Probability)) +
  geom_line(size = 1, color = "black") +
  labs(title = "PDF распределения хи-квадрат", x = "x", y = "Плотность вероятности") +
  theme_minimal() +
  geom_vline(xintercept = c(critical_value_lower, critical_value_upper, observed_chi_squared),
             linetype = c("solid", "solid", "dashed"),
             color = c("blue", "blue", "red"),
             size = c(2, 2, 2)) +
  annotate("text", x = critical_value_lower - 0.5, y = 0.1, label = sprintf("Q(%.3f)=%.2f", quantiles[1], critical_value_lower), hjust = 0, angle = 90) +
  annotate("text", x = critical_value_upper - 0.5, y = 0.1, label = sprintf("Q(%.3f)=%.2f", quantiles[2], critical_value_upper), hjust = 0, angle = 90) +
  annotate("text", x = observed_chi_squared - 0.5, y = 0.1, label = 'наблюдаемое', hjust = 0, angle = 90) +
  annotate("text", x = critical_value_upper - 1, y = 0.5, label = sprintf("df = %.0f", df), hjust = 0)
```


Наблюдаемое значение хи-квадрат статистики (красная пунктирная линия) попадает внутрь критических значений хи-квадрат статистики (синие линии) при уровне значимости 0.05, что означает, что мы не можем отклонить нулевую гипотезу о равенстве частот осложнений.


# Повторные измерения для таблиц сопряжённости (Тест Мак-Немара)

**Выборки зависимы:** одни и те же объекты измеряются дважды (до и после воздействия)

H0: Вероятность события до воздействия равна вероятности события после воздействия
H0: Вероятность события до воздействия не равна вероятности события после воздействия

Похож на Chi squared !!!

```{r}


#?mcnemar.test

# Пример данных с двумя категориальными переменными (до и после воздействия)

my_matrix <- matrix(c(9, 1, 1, 9), 
             nrow = 2, ncol = 2, 
             dimnames = list("До" = c("Инфильтрация +", "Инфильтрация -"), 
                             "После" = c("Инфильтрация +", "Инфильтрация -")))

# нас интересуют только диагональные элементы - те, которые поменялись
print(my_matrix)

# Chi squared test - его не надо делать для зависимых выборок! хотя в этом случае он дает значимый результат
print(chisq.test(my_matrix, simulate.p.value = TRUE, B = 10000))

# McNemar's test
print(mcnemar.test(my_matrix))


```










